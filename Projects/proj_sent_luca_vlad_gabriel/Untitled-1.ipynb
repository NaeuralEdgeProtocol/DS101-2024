{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stanza in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (1.8.2)\n",
      "Requirement already satisfied: emoji in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (2.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (4.25.4)\n",
      "Requirement already satisfied: requests in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (3.3)\n",
      "Requirement already satisfied: toml in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (2.3.1+cu121)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from stanza) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.3.0->stanza) (2021.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from requests->stanza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from requests->stanza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from requests->stanza) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from requests->stanza) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.3.0->stanza) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.3.0->stanza) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (3.6.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (2.0.32)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\lucav\\appdata\\roaming\\python\\python312\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza\n",
    "!pip install scikit-learn # Install scikit-learn if you haven't already\n",
    "!pip install gensim\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "import stanza\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Joblib\n",
    "from joblib import dump\n",
    "\n",
    "# Google Colab\n",
    "# from google.colab import files\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning\n",
    "from keras import models, layers\n",
    "from keras.layers import Dense, Dropout, LSTM, Conv1D, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cleaned_reviews_rating_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Download and load cleaned reviews\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m     os\u001b[39m.\u001b[39msystem(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwget -q \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/ACS-SII/proiect-2024-sentiment-analysis-study/refs/heads/main/new_set/cleaned_reviews_rating_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcleaned_reviews_rating_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.json\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m         test_data[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W3sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Download and load vocabulary\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cleaned_reviews_rating_1.json'"
     ]
    }
   ],
   "source": [
    "test_data = {}\n",
    "voc = {}\n",
    "\n",
    "for i in range(5):\n",
    "    # Download and load cleaned reviews\n",
    "    os.system(f'wget -q \"https://raw.githubusercontent.com/ACS-SII/proiect-2024-sentiment-analysis-study/refs/heads/main/new_set/cleaned_reviews_rating_{i+1}.json\"')\n",
    "    with open(f\"cleaned_reviews_rating_{i+1}.json\", \"r\") as f:\n",
    "        test_data[i+1] = json.load(f)\n",
    "\n",
    "    # Download and load vocabulary\n",
    "    os.system(f'wget -q \"https://raw.githubusercontent.com/ACS-SII/proiect-2024-sentiment-analysis-study/refs/heads/main/new_set/voc_rating_{i+1}.json\"')\n",
    "    with open(f\"voc_rating_{i+1}.json\", \"r\") as f:\n",
    "        voc[i+1] = json.load(f)\n",
    "\n",
    "    # # Optional: print confirmation\n",
    "    # print(f\"Loaded data for rating {i+1}:\")\n",
    "    # print(\"Sample review data:\", test_data[:1])  # Show first entry as a sample\n",
    "    # print(\"Sample vocabulary:\", dict(list(voc.items())[:5]))  # Show first 5 entries as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'laroseda_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mwget \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/ancatache/LaRoSeDa/main/data_splitted/laroseda_train.json\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mlaroseda_train.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39m# returns JSON object as\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39m# a dictionary\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m train_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'laroseda_train.json'"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/ancatache/LaRoSeDa/main/data_splitted/laroseda_train.json\"\n",
    "f = open('laroseda_train.json')\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "train_data = json.load(f)\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/ancatache/LaRoSeDa/main/data_splitted/laroseda_test.json\"\n",
    "f = open('laroseda_test.json')\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "test_data = json.load(f)\n",
    "\n",
    "# Closing file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_doc(doc):\n",
    "    cleaned = list()\n",
    "    for i in doc:\n",
    "        rev = i['title'] + ' . ' + i['content']\n",
    "        # rev=i['content']\n",
    "        # rev = re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', rev)\n",
    "        rev = rev.lower()\n",
    "        # rev = re.sub(r'\\s+', ' ', rev)\n",
    "        # rev = re.sub(r'(?<! )(?=[.,!?()\"\\'/:;/\\\\\\[^\\]])|(?<=[.,!?()\"\\'/:;/\\\\\\[^\\]])(?! )', r' ', rev)\n",
    "        cleaned.append(rev)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def read_data(set):\n",
    "    pos_data = list()\n",
    "    neg_data = list()\n",
    "    for i in set:\n",
    "        # print(i)\n",
    "        match i['starRating']:\n",
    "            case '1':\n",
    "                neg_data.append(i)\n",
    "            case '2':\n",
    "                neg_data.append(i)\n",
    "            case '4':\n",
    "                pos_data.append(i)\n",
    "            case '5':\n",
    "                pos_data.append(i)\n",
    "    return neg_data, pos_data\n",
    "\n",
    "\n",
    "def read_docs():\n",
    "    f = open('laroseda_train.json')\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    train_data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    f = open('laroseda_test.json')\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    test_data = json.load(f)\n",
    "    # Closing file\n",
    "    f.close()\n",
    "\n",
    "    train_neg, train_pos = read_data(train_data['reviews'])\n",
    "    test_neg, test_pos = read_data(test_data['reviews'])\n",
    "\n",
    "    train_pos_clean = prep_doc(train_pos)\n",
    "    train_neg_clean = prep_doc(train_neg)\n",
    "    test_pos_clean = prep_doc(test_pos)\n",
    "    test_neg_clean = prep_doc(test_neg)\n",
    "\n",
    "    return train_pos_clean, train_neg_clean, test_pos_clean, test_neg_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "neg_data, pos_data = read_data()\n",
    "#new\n",
    "data_pos=test_data[4]+test_data[5]\n",
    "data_neg=test_data[1]+test_data[2] #+test_data[3]\n",
    "\n",
    "negative=neg_data+data_neg\n",
    "positive=pos_data+data_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = positive+negative\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
